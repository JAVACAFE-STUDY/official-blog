---
title: 빅데이터 - 람다 아키텍처로 알아보는 실시간 빅데이터 구축의 핵심 원리와 기법 - 요약(2)
date : 2018-02-08 00:00:00
author : 변현정
---

# 빅데이터 - 람다 아키텍처로 알아보는 실시간 빅데이터 구축의 핵심 원리와 기법 [저자. 네이선마츠, 제임스 워렌]

***

## 마스터 데이터 집합 저장소의 요구 사항과 하둡 분산 파일시스템 
##### 4장&5장의 내용을 요약하였습니다. 

​	Check List

* [ ] 마스터 데이터 집합 저장소의 **요구사항** 
* [ ] **분산 파일 시스템** 
* [ ] **수직 분할** 로 효율성 개선하기
* [ ] **하둡 분산 파일시스템** 사용하기

마스터 데이터 집합은 *하나의 서버에 저장하기에는 너무 큰 경우*가 많기 때문에, 데이터를 *여러 장비에 어떻게 분산*시킬 것인지가 매우 중요합니다. *마스터 데이터 집합을 저장*하는 방법은 *마스터 데이터 집합을 사용*하는 방법에도 영향을 미치기 때문에 반드시 사용 패턴을 염두에 두고 저장전략을 고안해야 합니다.



### 1. 마스터 데이터 집합 저장소의 요구 사항

데이터 저장소의 요구 사항을 결정하기 위해서는 데이터가 어떻게 쓰여지고 어떻게 읽혀질지를 고려해야 합니다.

데이터의 핵심 속성 : **불변성** + 영원히 **진실** 

* 각 데이터는 오직 한 번만 기록
* 데이터의 변경이 필요 없음
* 새로운 데이터를 데이터 집합에 추가하는 것만이 유일한 쓰기 연산

일괄처리 계층은 데이터 집합에 대한 함수를 계산해서 일괄처리 뷰를 생성하는 역할도 합니다.
=> 일괄처리 계층의 저장소 시스템은 한 번에 많은 데이터를 읽는 데 적합해야 합니다.

**“데이터를 한 번만 쓰고, 읽기는 큰 단위로 여러번 수행한다.”**



### 2. 일괄처리 계층을 위한 저장소 솔루션 선택


#### 분산 키/값 저장소

* 여러 장비에 분산되는 거대하고 영속적인 해시맵
* 무작위 읽기와 쓰기를 지원
* 여러 개의 키/값 쌍을 묶어서 압축하는 것 불가능
* 저장소 비용과 처리 비용 사이에서 반대급부를 조율하는 데 심각한 제한
* 변경 가능한 저장소에 사용하도록 만들어진 것이기 때문에, 마스터 데이터 집합에 불변성을 강제하는게 극히 필요한 경우라면 문제

#### 파일시스템

* 파일은 바이트의 순차열
* 파일을 처리하는 가장 효율적인 방법은 쭉 스캔하는 것
* 파일은 디스크에 순차적으로 저장
* 파일에 들어 있는 바이트는 완전히 제어가능
* 파일에 들어 있는 바이트는 압축도 자유
* 저장소 비용과 처리 비용 사이의 조정 범위를 제한하지 않음
* 세밀한 권한 시스템이 구현되어 있어서 불변성을 강제

#### 분산 파일시스템

* **클러스터에 장비를 추가**함으로써 규모가 확장
* **장비가 다운되더라도 내결함성**을 지니도록 설계됨
* 장비 한 대가 죽더라도 모든 파일과 데이터에 접근 가능
* 일반 파일시스템과 차이 : **파일 중간에 쓸수 없고, 파일을 만든 후에 변경할 수도 없음**
* 흔히 작은 파일은 비효율적이기 때문에 파일 크기를 상대적으로 크게 유지(64MB  정도가 일반적)



### 3. 분산 파일시스템의 동작 방식

하둡 분산 파일시스템(Hadoop Distributed File System - HDFS) : 확장성있는 분산 파일시스템으로 클러스터에 데이터가 어떻게 저장될지를 관리합니다.

HDFS, 하둡 맵리듀스 : 대용량 데이터를 저장하고 처리하기 위한 자바 프레임워크인 하둡 프로젝트의 구성요소입니다.

HDFS 클러스터의 두 가지 종류의 노드

* 네임노드(namenode) : 파일에서 블록으로 연결해주는 관계와 각 블록의 위치를 추적
* 데이터노드(datanode) : 파일을 HDFS에 올리면, 그 파일은 먼저 고정된 크기의 블록으로 쪼개지며, 블록 크기는 대개 64MB 에서 256MB 사이입니다. 그 후 각 블록은 임의로 선택 된 복수 개의 데이터노드로 복제됩니다. 즉, 파일의 내용을 보관하는 것이 데이터노드 입니다.

분산 파일시스템의 중요사항

* [ ] 파일은 확장성을 위해 **여러 장비로 분산 저장**되며, 이로써 **병렬 처리**도 가능해집니다.
* [ ] 파일 블록은 내결함성을 위해 **여러 노드로 복제**됩니다.



### 4. 분산 파일시스템을 사용하여 마스터 데이터 집합을 저장하기

파일을 한번 생성한 후에 변경 할 수 없는 가장 기본적인 기능만 가진 분산 파일시스템을 사용하는것을 예를 들어봅니다.

파일을 변경할 수 없다면 마스터 데이터 집합 전체를 하나의 파일에 저장할 수 없습니다.
=> 마스터 데이터 집합을 여러 파일로 나누고 모든 파일을 동일한 폴더에 저장하면 됩니다.



### 5. 수직분할

일괄처리 계층은 전체 데이터 집합에 대한 함수를 실행하도록 만들어졌지만 데이터 전체를 사용할 필요가 없는 계산도 많습니다.
ex) 지난 두 주 동안의 수집된 정보만 필요한 계산

수직 분할(vertical partitioning) : 일괄처리 저장소는 데이터를 분할하여 함수가 자신의 계산과 관련있는 데이터에만 접근하도록 하는 과정입니다.

수직 분할은 일괄처리 계층에 필수사항은 아닙니다. => 일괄처리 계층은 한 번에 모든 데이터를 사용할 수 있으며, 그중 필요 없는 것은 걸러낼 수 있습니다. 그러나 수직분할을 하용하면 성능을 많이 향상시킬수 있다.

분산 파일 시스템에서의 수직 분할은 **데이터를 개개의 폴더에 저장**하는 것으로 구현합니다.
ex)분산 파일시스템에 로그인 정보를 저장할 때 폴더를 날짜별로 생성하여(날짜를 기준으로 수직분할) 그날 그날의 데이터를 날짜별로 생성한 폴더에 둡니다. 각각의 하루를 나타내는 폴더는 그날에 발생한 로그인 정보를 포함하는 파일들을 가집니다.



### 6. 분산 파일시스템의 하위 수준 속성

일반적인 유닉스 파일시스템 연산을 예를 들어 마스터 데이터 집합에 데이터 추가를 하거나 마스터 데이터 집합을 수직 분할할 때 겪게되는 어려움을 살펴봅니다.

ex) 마스터 데이터 집합에 데이터를 추가하기
마스터 데이터 집합은 /master 폴더에 있고, 마스터 데이터 집합에 추가하고 싶은 데이터는 /new-data 폴더에 있다.

[의사코드]
*foreach file:"/new-data"* 	// /new-data에 있는 모든 파일을 순회합니다.
*mv file "master"* 			// 파일을 /master 폴더로 옮깁니다.

만약, 마스터 데이터 집합 폴더에 이름이 같은 파일이 있으면 mv 연산은 실패할 것입니다.
만약, /new-data 에 있는 파일과 /master 에 있는 파일의 형식이 다르면 mv 연산은 실패할 것입니다.
만약, 수직 분할이 된 마스터 데이터 집합인 /master 에 수직분할을 따르지 않는 /new-data 에 있는 파일을 /master의 최상위 경로로 바로 옮기려 한하면, /new-data에 있는 파일은 /master 의 최상위 경로로 옮기려 하는것을 허용하지 않던가, /new-data 에 대해 데이터 추가 연산의 부분으로 수직 분할을 적용해야 합니다. => 여기서 파일 및 폴더용 API 를 직접 사용하면 실수를 저지르기 쉽고, 데이터 집합의 수직분할도 쉽게 깨질 수 있습니다.

이 예에서 보듯이 파일과 폴더는 데이터 집합을 조작하기에는 추상화 수준이 너무 낮습니다. => 이러한 작업을 자동화해주는 라이브러리를 사용하자!



### 7. 하둡 분산 파일시스템 사용하기


#### HDFS의 동작 방식에 대한 기초

* 파일은 블록으로 쪼개져서 **클러스터에 있는 여러 노드**로 퍼뜨려진다.
* 블록은 여러 노드로 **복제** => 장비가 다운되더라도 데이터는 여전히 사용 가능합니다.
* **네임노드**는 각 파일이 어떤 블록으로 구성되는지, 그 블록들이 어디에 저장되는지 추적합니다.

#### 작은 파일 문제

* 하둡은 데이터가 HDFS 상의 **여러 작은 파일**에 저장되어 있을 때는 **계산 성능이 떨어지는** 특성이 있습니다.
  * 원인 : 맵리듀스 작업이 입력 데이터 집합의 각 블록마다 태스크를 하나씩 실행하기 때문. 각 태스크는 실행을 계획하고 조정하는 오버헤드를 소모하는데, 각각의 작은 파일은 독립적인 태스트에서 실행되어야 하므로 그 비용은 반복적으로 발생합니다.
* 데이터 집합에 작은 파일이 많아지면 이들을 **통합**하는게 좋습니다.

#### 상위 수준 추상화를 향하여

마스터 데이터 집합을 조작할 때 중요한 세가지

* 새로운 데이터를 데이터 집합에 추가하기
* 데이터 집합에 수직 분할을 적용하고 기존의 분할이 깨지는 것을 방지하기
* 작은 파일을 효율적으로 큰 파일로 통합하기

파일과 폴더를 직접 다루어서 이런 작업을 하기는 매우 불편하고 오류가 발생하기 쉽습니다.그러므로 우아한 방식으로 처리할 수 있는 자동화 라이브러리를 사용하는것이 좋습니다.

라이브러리를 사용하면 데이터가 어떻게 저장되고 유지보수되는 지에 대해 신경 쓰지 않고 데이터 자체에 집중할 수 있습니다.

라이브러리를 선택하여 사용하게 될 때 다음의 사항을 고려하여 선택합니다.

* **마스터 데이터 집합**은 람다 아카텍처(lambda architecture)에서 모든 **정보의 원천**이며, 일괄처리 계층(batch layer)은 거대하고 꾸준히 증가하는 데이터 집합을 문제없이 처리해야 합니다.
* 실제 질의에 응답하기 위해서는 데이터를 **일괄처리 뷰(batch view)로 변환**하는 쉽고 효율적인 수단이여야 합니다.
* 데이터 집합에 새로운 **데이터 추가하기, 수직 분할, 파일 통합**을 안전하고, 쉽고, 성능 기준에 맞게 수행할 수 있는 것이어야 합니다.




